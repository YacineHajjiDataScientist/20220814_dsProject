{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3509e254",
   "metadata": {},
   "source": [
    "# Tuning models optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d645c4",
   "metadata": {},
   "source": [
    "##### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ec5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dill\n",
    "import datetime\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error, classification_report, roc_curve, auc, plot_confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502de69",
   "metadata": {},
   "source": [
    "##### Define workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd87b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Megaport\\\\Desktop\\\\jupyterNotebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:\\\\Users\\\\Megaport\\\\Desktop\\\\jupyterNotebook')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513b635",
   "metadata": {},
   "source": [
    "##### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0383883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(836553, 70)\n",
      "(836553,)\n"
     ]
    }
   ],
   "source": [
    "# dfPoolMLCCA = pd.read_pickle('D:\\\\jupyterDatasets\\\\20221031_table_dfPoolMLCCA.csv')\n",
    "feature_matrix = pd.read_pickle('D:\\\\jupyterDatasets\\\\20221112_table_feature_matrix.csv')\n",
    "target = pd.read_pickle('D:\\\\jupyterDatasets\\\\20221119_table_target.csv')\n",
    "\n",
    "# print(dfPoolMLCCA.shape)\n",
    "print(feature_matrix.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ce87bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['choc_cote', 'ageMeanConductors', 'nbVeh', 'prof_2.0', 'prof_3.0',\n",
       "       'planGrp_1.0', 'surf_2.0', 'surf_8.0', 'atm_2.0', 'atm_3.0', 'atm_5.0',\n",
       "       'atm_7.0', 'atm_8.0', 'vospGrp_1.0', 'catv_EPD_exist_1',\n",
       "       'catv_PL_exist_1', 'trajet_coursesPromenade_conductor_1',\n",
       "       'sexe_male_conductor_1', 'sexe_female_conductor_1',\n",
       "       'intGrp_Croisement circulaire', 'intGrp_Croisement de deux routes',\n",
       "       'intGrp_Hors intersection', 'intGrp_Passage à niveau',\n",
       "       'catv_train_exist_1', 'infra_3.0', 'infra_5.0', 'infra_7.0',\n",
       "       'infra_9.0', 'catr_2.0', 'catr_3.0', 'catr_4.0', 'catr_9.0',\n",
       "       'hourGrp_nuit', 'lum_2.0', 'lum_3.0', 'lum_5.0', 'circ_2.0', 'circ_3.0',\n",
       "       'circ_4.0', 'nbvGrp_1', 'nbvGrp_2', 'nbvGrp_3', 'nbvGrp_4+',\n",
       "       'catv_2_roues_exist_1', 'col_2.0', 'col_3.0', 'col_4.0', 'col_5.0',\n",
       "       'col_6.0', 'col_7.0', 'obsGrp_Pas d'Obstacle', 'situ_2.0', 'situ_3.0',\n",
       "       'situ_4.0', 'situ_6.0', 'situ_8.0', 'populationGrp_Grande Ville',\n",
       "       'populationGrp_Métropole', 'populationGrp_Petite Ville',\n",
       "       'populationGrp_Village', 'populationGrp_Ville Moyenne',\n",
       "       'mois_label_aug', 'mois_label_dec', 'mois_label_fev', 'mois_label_jan',\n",
       "       'mois_label_jul', 'mois_label_mar', 'mois_label_oct',\n",
       "       'etatpGrp_pieton_alone_1', 'locpGrp_pieton_3_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5354868a",
   "metadata": {},
   "source": [
    "##### Splitting into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54345e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(feature_matrix, target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb493bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "test = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da96932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence y train: 0.4234\n",
      "Prevalence y test: 0.423\n"
     ]
    }
   ],
   "source": [
    "print('Prevalence y train:', round(sum(y_train) / len(y_train), 4))\n",
    "print('Prevalence y test:', round(sum(y_test) / len(y_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087de319",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096e642",
   "metadata": {},
   "source": [
    "### 1- XGBoost\n",
    "**Les paramètres généraux**  \n",
    "- booster : Le type de booster utilisé (par défaut gbtree).  \n",
    "- nthread : Le nombre de coeurs à utiliser pour le calcul parallèle (par défaut tous les coeurs disponibles sont utilisés).  \n",
    "\n",
    "**Les paramètres du booster (on se limitera ici au cas des arbres)**  \n",
    "- num_boost_round : Le nombre maximum d'itérations/d'arbres construits (vaut 100 par défaut).  \n",
    "- learning_rate : Contrôle le 'taux d’apprentissage'. A chaque étape de boosting, on introduit une constante dans la formule de mise à jour des modèles. Elle réduit le poids obtenu par rapport aux performances pour prévenir l'overfitting. Une valeur faible entraîne un modèle plus robuste au sur-apprentissage, mais un calcul et une convergence plus lents. Pensez à augmenter le nombre d'arbres lorsque learning_rate est faible (vaut 0.3 par défaut, et doit être compris entre 0 et 1).  \n",
    "- min_split_loss : Réduction de perte minimale requise pour effectuer une partition supplémentaire sur un nœud de l'arbre. Plus il est grand, plus l'algorithme sera conservateur.  \n",
    "- max_depth : Contrôle la profondeur des arbres. Plus les arbres sont profonds, plus le modèle est complèxe et plus grandes sont les chances d'overfitting (vaut 6 par défaut).  \n",
    "- min_child_weight : Critère d'arrêt relatif à la taille minimum du nombre d'observation dans un noeud (vaut 1 par défaut).  \n",
    "- subsample : Permet d'utiliser un sous-échantillon du dataset d'entraînement pour chaque arbre (vaut 1 par défaut, pas de sous-échantillonnage ; et doit être compris entre 0 et 1).  \n",
    "- colsample_bytree : Permet d'utiliser un certain nombre de variables parmi celles d'origine (vaut 1 par défaut, toutes les variables sont séléctionnées ; et doit être compris entre 0 et 1).  \n",
    "- reg_lambda et reg_alpha : contrôlent respectivement la régularisation L1 et L2 sur les poids (équivalent aux régression Ridge et Lasso).  \n",
    "\n",
    "- Fonction objectif à utiliser\n",
    "    - binary:logistic pour la classification binaire. Retourne les probabilités pour chaque classe.\n",
    "    - reg:linear pour la régression.\n",
    "    - multi:softmax pour la classification multiple en utilisant la fonction softmax. Retourne les labels prédits.\n",
    "    - multi:softprob pour la classification multiple en utilisant la fonction softmax. Retourne les probabilités pour chaque classe.\n",
    "- eval_metric : Métrique d'évaluation (par défaut l'erreur de prédiction pour la classification, le RMSE pour la régression).\n",
    "Les métriques disponibles sont : mae (Mean Absolute Error), Logloss, AUC, RMSE, error mologloss, etc...\n",
    "- early_stopping_rounds : pour arrêter l'apprentissage quand l'évaluation sur l'ensemble de test ne s'améliore plus durant un certain nombre d'itérations. L'erreur de validation doit diminuer au moins tous les early_stopping_rounds pour continuer l'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f74ad",
   "metadata": {},
   "source": [
    "##### Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "699a1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.75326\teval-auc:0.75193\n",
      "[1]\ttrain-auc:0.75916\teval-auc:0.75808\n",
      "[2]\ttrain-auc:0.76525\teval-auc:0.76358\n",
      "[3]\ttrain-auc:0.76890\teval-auc:0.76710\n",
      "[4]\ttrain-auc:0.77253\teval-auc:0.77078\n",
      "[5]\ttrain-auc:0.77496\teval-auc:0.77323\n",
      "[6]\ttrain-auc:0.77653\teval-auc:0.77470\n",
      "[7]\ttrain-auc:0.77926\teval-auc:0.77725\n",
      "[8]\ttrain-auc:0.78084\teval-auc:0.77874\n",
      "[9]\ttrain-auc:0.78223\teval-auc:0.78000\n",
      "[10]\ttrain-auc:0.78386\teval-auc:0.78153\n",
      "[11]\ttrain-auc:0.78490\teval-auc:0.78252\n",
      "[12]\ttrain-auc:0.78554\teval-auc:0.78300\n",
      "[13]\ttrain-auc:0.78610\teval-auc:0.78349\n",
      "[14]\ttrain-auc:0.78678\teval-auc:0.78414\n",
      "[15]\ttrain-auc:0.78732\teval-auc:0.78462\n",
      "[16]\ttrain-auc:0.78802\teval-auc:0.78515\n",
      "[17]\ttrain-auc:0.78848\teval-auc:0.78557\n",
      "[18]\ttrain-auc:0.78880\teval-auc:0.78579\n",
      "[19]\ttrain-auc:0.78967\teval-auc:0.78662\n",
      "[20]\ttrain-auc:0.78993\teval-auc:0.78683\n",
      "[21]\ttrain-auc:0.79024\teval-auc:0.78703\n",
      "[22]\ttrain-auc:0.79068\teval-auc:0.78738\n",
      "[23]\ttrain-auc:0.79102\teval-auc:0.78766\n",
      "[24]\ttrain-auc:0.79146\teval-auc:0.78802\n",
      "[25]\ttrain-auc:0.79163\teval-auc:0.78810\n",
      "[26]\ttrain-auc:0.79182\teval-auc:0.78818\n",
      "[27]\ttrain-auc:0.79206\teval-auc:0.78830\n",
      "[28]\ttrain-auc:0.79227\teval-auc:0.78846\n",
      "[29]\ttrain-auc:0.79264\teval-auc:0.78874\n",
      "[30]\ttrain-auc:0.79295\teval-auc:0.78895\n",
      "[31]\ttrain-auc:0.79327\teval-auc:0.78916\n",
      "[32]\ttrain-auc:0.79355\teval-auc:0.78933\n",
      "[33]\ttrain-auc:0.79363\teval-auc:0.78937\n",
      "[34]\ttrain-auc:0.79388\teval-auc:0.78952\n",
      "[35]\ttrain-auc:0.79403\teval-auc:0.78962\n",
      "[36]\ttrain-auc:0.79421\teval-auc:0.78970\n",
      "[37]\ttrain-auc:0.79446\teval-auc:0.78985\n",
      "[38]\ttrain-auc:0.79461\teval-auc:0.78994\n",
      "[39]\ttrain-auc:0.79502\teval-auc:0.79021\n",
      "[40]\ttrain-auc:0.79518\teval-auc:0.79028\n",
      "[41]\ttrain-auc:0.79529\teval-auc:0.79032\n",
      "[42]\ttrain-auc:0.79545\teval-auc:0.79037\n",
      "[43]\ttrain-auc:0.79561\teval-auc:0.79045\n",
      "[44]\ttrain-auc:0.79581\teval-auc:0.79057\n",
      "[45]\ttrain-auc:0.79597\teval-auc:0.79068\n",
      "[46]\ttrain-auc:0.79602\teval-auc:0.79069\n",
      "[47]\ttrain-auc:0.79621\teval-auc:0.79082\n",
      "[48]\ttrain-auc:0.79634\teval-auc:0.79087\n",
      "[49]\ttrain-auc:0.79642\teval-auc:0.79088\n"
     ]
    }
   ],
   "source": [
    "### Initiating parameters for basic XGBoost\n",
    "# params = {'objective' : 'binary:logistic', \n",
    "#           'booster' : 'gbtree', \n",
    "#           'learning_rate' : 1,\n",
    "#           'eval_metric' : 'AUC'}\n",
    "params = [\n",
    "    ('objective', 'binary:logistic'),\n",
    "    ('max_depth', 6),\n",
    "    ('eval_metric', 'auc'),\n",
    "    ('early_stopping_rounds', 10)\n",
    "]\n",
    "\n",
    "### Basic XGBoost without tuning\n",
    "clf_xgb = xgb.train(params=params, dtrain=train, \n",
    "                    num_boost_round=50, \n",
    "                    evals=[(train, 'train'), (test, 'eval')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73986797",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred_train = clf_xgb.predict(X_train)\n",
    "xgb_pred_test = clf_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b775818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>xgb_pred_train</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gravGrp_2_34</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488529</td>\n",
       "      <td>0.088071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168202</td>\n",
       "      <td>0.255198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "xgb_pred_train         0         1\n",
       "gravGrp_2_34                      \n",
       "0               0.488529  0.088071\n",
       "1               0.168202  0.255198"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_train, xgb_pred_train, colnames=['xgb_pred_train'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f251524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79    385885\n",
      "           1       0.74      0.60      0.67    283357\n",
      "\n",
      "    accuracy                           0.74    669242\n",
      "   macro avg       0.74      0.72      0.73    669242\n",
      "weighted avg       0.74      0.74      0.74    669242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, xgb_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e3463d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>xgb_pred_test</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gravGrp_2_34</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485892</td>\n",
       "      <td>0.091094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171214</td>\n",
       "      <td>0.251801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "xgb_pred_test         0         1\n",
       "gravGrp_2_34                     \n",
       "0              0.485892  0.091094\n",
       "1              0.171214  0.251801"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, xgb_pred_test, colnames=['xgb_pred_test'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35e01fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79     96536\n",
      "           1       0.73      0.60      0.66     70775\n",
      "\n",
      "    accuracy                           0.74    167311\n",
      "   macro avg       0.74      0.72      0.72    167311\n",
      "weighted avg       0.74      0.74      0.73    167311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dcb1af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724995981244733\n",
      "0.7186868174680067\n"
     ]
    }
   ],
   "source": [
    "# AUC train\n",
    "fpr_xgb_train, tpr_xgb_train, seuils = roc_curve(y_train, xgb_pred_train, pos_label=1)\n",
    "roc_auc_xgb_train = auc(fpr_xgb_train, tpr_xgb_train)\n",
    "# AUC test\n",
    "fpr_xgb_test, tpr_xgb_test, seuils = roc_curve(y_test, xgb_pred_test, pos_label=1)\n",
    "roc_auc_xgb_test = auc(fpr_xgb_test, tpr_xgb_test)\n",
    "\n",
    "print(roc_auc_xgb_train)\n",
    "print(roc_auc_xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(fpr_xgb_test, tpr_xgb_test, color='orange', lw=2, label=round(roc_auc_xgb_test, 2))\n",
    "plt.plot(np.arange(0, 1, 0.01), np.arange(0, 1, 0.01), 'b--', label='0.50')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a669b1",
   "metadata": {},
   "source": [
    "##### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "984612fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'gamma': [0, 0.25, 1.0],\n",
    "    'reg_lambda': [0, 1.0, 10.0],\n",
    "    'scale_pos_weight': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1e98b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params = GridSearchCV(\n",
    "    estimator=clf_xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=10,\n",
    "    cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params.fit(X_train, \n",
    "                   y_train,\n",
    "                   eval_metric='auc',\n",
    "                   eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "120eee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[16:14:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_boost_round=50, num_parallel_tree=None,\n",
       "                                     predictor=None, random_state=None,\n",
       "                                     reg_alpha=None, ...),\n",
       "             n_jobs=2, param_grid={'max_depth': [2, 3, 4]}, scoring='roc_auc',\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    num_boost_round=50,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [2, 3, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=parameters,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = -1,\n",
    "    cv = 5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6a668cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_boost_round=50, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=1, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74276e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([181.85422401, 323.30103192,  67.18678126]),\n",
       " 'std_fit_time': array([92.71668813, 86.40454585,  6.0970038 ]),\n",
       " 'mean_score_time': array([4.21838226, 2.55384502, 0.51226511]),\n",
       " 'std_score_time': array([1.22020777, 2.28113775, 0.08223257]),\n",
       " 'param_max_depth': masked_array(data=[2, 3, 4],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 2}, {'max_depth': 3}, {'max_depth': 4}],\n",
       " 'split0_test_score': array([0.78250581, 0.78760482, 0.79023297]),\n",
       " 'split1_test_score': array([0.78419678, 0.78953565, 0.79287195]),\n",
       " 'split2_test_score': array([0.78079168, 0.78614412, 0.78952315]),\n",
       " 'split3_test_score': array([0.78241267, 0.787517  , 0.79130971]),\n",
       " 'split4_test_score': array([0.7812303 , 0.78708282, 0.79095375]),\n",
       " 'mean_test_score': array([0.78222745, 0.78757688, 0.79097831]),\n",
       " 'std_test_score': array([0.00118708, 0.00110798, 0.00112866]),\n",
       " 'rank_test_score': array([3, 2, 1])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
